# [30 Days of ML](https://www.kaggle.com/c/30-days-of-ml)


30 Days of ML on Kaggle was an in class prediction competition on a regression task.

First, I used the Random Forest Regression algorithm

[See RandomForest code here](https://github.com/andriescoetsee/my_first_kaggle_competition/blob/4921edfc802a2aa1c968ae869392150fbf53ad9f/30-days-of-ml-random-forest.ipynb)


Then, I used the XGBoost algorithm using the same framework.

[See XGBoost code here](https://github.com/andriescoetsee/my_first_kaggle_competition/blob/4921edfc802a2aa1c968ae869392150fbf53ad9f/30-days-of-ml-random-forest.ipynb)

## Conclusion

By using the XGBoost algorithm I could benefit from GPU processing as well as better results.





